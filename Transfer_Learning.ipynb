{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2c9b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from numpy import zeros, newaxis\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from joblib import Parallel,delayed\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras import utils as np_utils                     \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from keras.layers import Dense,Flatten,Conv1D,MaxPooling1D,Dropout,BatchNormalization\n",
    "from tensorflow.keras import datasets,layers,models\n",
    "from keras.models import Sequential\n",
    "from numpy import unique\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from keras import backend as K \n",
    "from keras.regularizers import l2\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "from sklearn.utils import shuffle\n",
    "from numpy.random import RandomState\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def baseline_als(y, lam, p, niter=10):\n",
    "    L = len(y)\n",
    "    D = sparse.diags([1, -2, 1], [0, -1, -2], shape=(L, L - 2))\n",
    "    w = np.ones(L)\n",
    "    for i in range(niter):\n",
    "        W = sparse.spdiags(w, 0, L, L)\n",
    "        Z = W + lam * D.dot(D.transpose())\n",
    "        z = spsolve(Z, w * y)\n",
    "        w = p * (y > z) + (1 - p) * (y < z)\n",
    "    return z\n",
    "\n",
    "# load in CNN\n",
    "weightsfile ='CNNBinaryFinalmodel.h5'\n",
    "modelfile = 'CNNBinaryFinalmodel.json'\n",
    "\n",
    "# load model from json\n",
    "json_file = open(modelfile, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "base_model = keras.models.model_from_json(loaded_model_json)\n",
    "base_model.load_weights(weightsfile)\n",
    "print(base_model.summary())\n",
    "# remove the last 2 dense FC layers and freeze it\n",
    "base_model.pop()\n",
    "base_model.pop()\n",
    "base_model.trainable = False\n",
    "\n",
    "inp = base_model.input\n",
    "\n",
    "last = base_model.layers[-1].output\n",
    "x = Dense(1, activation='sigmoid', name='predictions')(last)\n",
    "\n",
    "model2 = Model(inp, x)\n",
    "\n",
    "model2.layers[1].trainable = True\n",
    "model2.layers[2].trainable = True\n",
    "model2.layers[3].trainable = True\n",
    "model2.layers[4].trainable = True\n",
    "model2.layers[5].trainable = True\n",
    "model2.layers[6].trainable = True\n",
    "model2.layers[7].trainable = False\n",
    "model2.layers[8].trainable = False\n",
    "model2.layers[9].trainable = False\n",
    "model2.layers[10].trainable = False\n",
    "model2.layers[11].trainable = False\n",
    "model2.layers[12].trainable = False\n",
    "model2.layers[13].trainable = False\n",
    "model2.layers[14].trainable = False\n",
    "\n",
    "print(model2.summary())\n",
    "\n",
    "fnames=sorted(glob('Data_Pathway/*'))\n",
    "files=[np.loadtxt(f) for f in fnames]\n",
    "map=[f[:,3] for f in files]\n",
    "map=[np.reshape(m,(-1,1011)) for m in map]\n",
    "map_full = np.concatenate([m[:,:] for m in map],axis=0)\n",
    "\n",
    "y = np.concatenate([np.repeat(i, len(m)) for i, m in enumerate(map)], axis=0)\n",
    "map_full= savgol_filter(map_full, 11, 3, axis=0)\n",
    "back = Parallel(n_jobs=8)(delayed(baseline_als)(j, 100000, 0.001) for j in map_full)\n",
    "map_full= np.subtract(map_full, back)\n",
    "map_full= np.reshape(map_full, (-1, 1011))\n",
    "divide=map_full[:,999:1000]\n",
    "X=map_full/divide\n",
    "\n",
    "x_train, x_test, y_train, y_test=train_test_split(X,y,test_size=0.5,stratify=y,shuffle=True)\n",
    "x_val, x_test, y_val, y_test=train_test_split(x_test,y_test,test_size=0.8,stratify=y_test,shuffle=True)\n",
    "\n",
    "pca = PCA(n_components=22)\n",
    "pca.fit(x_train)\n",
    "x_train= pca.transform(x_train)\n",
    "x_val= pca.transform(x_val)\n",
    "x_test= pca.transform(x_test)\n",
    "\n",
    "x_train_cnn= np.reshape(x_train, (x_train.shape[0], x_train.shape[1],1))\n",
    "x_val_cnn= np.reshape(x_val, (x_val.shape[0], x_val.shape[1],1))\n",
    "x_test_cnn= np.reshape(x_test, (x_test.shape[0], x_test.shape[1],1))\n",
    "\n",
    "base_learning_rate = 0.001\n",
    "model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "finetune_history=model2.fit(x_train_cnn, y_train,epochs=500,validation_data=(x_val_cnn,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7051b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(hist['epoch'], hist['accuracy'],\n",
    "           label='Train Accuracy')\n",
    "    plt.plot(hist['epoch'], hist['val_accuracy'],\n",
    "           label = 'Val Accuracy')\n",
    "    plt.ylim([0,1.1])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(finetune_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba002b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname=sorted(glob('\"Unknown\"Data_Pathway/*'))\n",
    "file=[np.loadtxt(f) for f in fname]\n",
    "map=[f[:,3] for f in file]\n",
    "map=[np.reshape(m,(-1,1011)) for m in map]\n",
    "map_full= np.concatenate([m[:,:] for m in map],axis=0)\n",
    "map_full=np.array(map_full)\n",
    "Y_test=np.repeat(0,400)\n",
    "map_full= savgol_filter(map_full, 11, 3, axis=1)\n",
    "back = Parallel(n_jobs=8)(delayed(baseline_als)(j, 100000, 0.001) for j in map_full)\n",
    "map_full= np.subtract(map_full, back)\n",
    "map_full= np.reshape(map_full, (-1, 1011))\n",
    "divide=map_full[:,999:1000]\n",
    "X_test=map_full/divide\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d398ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i,  \"{:0.2f}\".format(cm[i, j]),\n",
    "                 horizontalalignment=\"center\",fontsize=20,\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "X_cleaned= pca.transform(X_cleaned)\n",
    "X_cleaned_cnn= np.reshape(X_cleaned, (X_cleaned.shape[0], X_cleaned.shape[1],1))\n",
    "y_pred1 = (model2.predict(X_cleaned_cnn) > 0.5).astype(\"int32\")\n",
    "\n",
    "cn_matrix = confusion_matrix(y_cleaned,y_pred1)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "class_names=['below','above']\n",
    "plot_confusion_matrix(cn_matrix, classes=class_names, normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
